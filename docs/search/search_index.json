{
    "docs": [
        {
            "location": "/", 
            "text": "EXOSIMS Sandbox\n\n\nWe developed an environment for running batches of Exosims simulations.\nThere are three main functional pieces to this sandbox:\nsimulation execution, data reduction, and\ngraphics; also, there is some ancillary support for iPython parallel engines.\nIn general, the workflow is to create an Exosims script, \nrun an ensemble of simulations that dump outputs to disk,\nreduce data from those simulations to\na set of CSV files, and generate plots.\n\n\nMost of the workflow execution is controlled by a \nMakefile\n, and\nthus invoked by running \nmake\n from the shell with an appropriate target.\nThe components making up this tower of abstraction are described \nelsewhere\n.\nThe \nmake\n mechanism both feeds off of and imposes a file structure,\nwhich we describe next.\n\n\nSandbox File Layout\n\n\nWe run simulations tailored to a couple of mission scenarios.\nWe show HabEx here for example, but the Luvoir simulations have\nthe same layout.\n\n\nHabEx/\n    README \n    EXOSIMS/          -- symlink to allow \"import EXOSIMS\"\n    Makefile            -- controls execution\n    Scripts/             -- JSON scripts for Exosims\n      .../HabEx_4m.json -- typical input script \n    sims/                -- Ensembles of DRM outputs\n      .../HabEx_4m/...  -- DRMs and data from above script\n    add-sims.sh*    -- adds more Exosims runs to sims/\n    Experiments/    -- groups of ensembles\n       .../HabEx.json  -- Lists selected scripts above\n    exps/                -- results of above\n       .../HabEx/...   --    \n    ipyparallel/       -- ipython parallel configuration\n    util/                  -- generic utility code\n    Local/               -- mission-specific code\n\n\n\nThe main conventions here are:\n\n\n\n\nThe Exosims code applicable to the mission is symlinked so that\nany module can \nimport EXOSIMS\n.\n\n\nThe Exosims input scripts are all under the \nScripts\n directory.\nAll runs using that script (an \nensemble\n)\nhave output in the corresponding directory\nunderneath \nsims\n.\n\n\nFor things like parameter sweeps, several related ensembles will\nbe generated for a variety of parameters: we call this an \nexperiment\n.\nThe related script names are under \nExperiments\n, and their\ncorresponding output files (graphics) are under \nexps\n.\n\n\nMost reduction and graphics code lives in \nutil\n and \nLocal\n;\nthe latter is intended to be mission-tailored, but the tailoring\nhas turned out to be minimal.\n\n\n\n\nSimulation Output Files\n\n\nThe subdirectories of \nsims\n are of particular interest, because they store\nExosims outputs like DRMs, reduced data like CSV files, and graphical\noutputs like plots and movies:\n\n\ndrm/                      -- DRM outputs (time-ordered observation lists)\n    .../seed1.pkl      -- a specific run as a python pickle\n    ...                       -- (and a bunch more runs)\nspc/                       -- SPC (star-planet configuration) files\n    .../seed1.spc        -- a specific SimulatedUniverse as a pickle\n    ...\nrun/                        -- run logs\n    .../outspec.json   -- outspec from given runs\nreduce-info.csv       -- CSV files summarizing the ensemble\nreduce-radlum.csv\nreduce-times.csv\nreduce-visits.csv\nreduce-pool.json\ngfx/                        -- various plots as images\npath/                      -- single-DRM movies\n    .../seed1.mp4\npath-ens/               --\n\n\n\nEach Exosims run produces a single DRM, stored in \ndrm/\n according to the\nrandom-number seed, and a corresponding star-planet configuration\n(the \nSimulatedUniverse\n), stored in \nspc/\n.\nDepending on how it was run, it may produce a text runlog in \nrun/\n, and\na JSON outspec.\n\n\nThis set of outputs (DRM, SPC, runlog, errorlog, outspec) is made by\na tailored \nSurveyEnsemble\n class\n(\nLocal/EXOSIMS_local/IPClusterEnsembleJPL2.py\n),\nand a shell-level driver and \"run_one\" (\nLocal/ipcluster_ensemble_jpl_driver.py\n).\nThese have been generalized and updated from the Exosims stock.\n\n\nAs mentioned, after an ensemble is run, a reduction script\nis typically invoked that generates the CSV output files,\nand subsequent graphics commands use the ensemble summaries,\nor in some cases just single DRMs.\n\n\nData Reduction\n\n\nWe separated data reduction from plotting so that reduction of\nthe ensemble could be done once, and then various plots could\nbe remade and tweaked quickly from the reduced data.\nThe python driver is \nreduce_drms.py\n.\nIt contains some re-usable code for loading the ensemble of DRMs\nand for computing summaries (means, standard errors,\nmedians, quantiles, histograms).\n\n\nData reduction happens at the ensemble level, by reading in\nthe set of typically ~100 DRMs and corresponding SPCs, and putting\nout the following CSV files.\n\n\nreduce-info.csv       -- metadata\nreduce-times.csv     -- temporal summaries like fuel use \nreduce-radlum.csv  -- histograms segmented by radius/luminosity\nreduce-visits.csv     -- histograms of revisits\nreduce-earth.csv     -- exo-Earth detection counts\nreduce-pool.json    -- JSON of all reduced data\n\n\n\nThe CSV format is good at storing vectors, so the above CSV files are\nall vectorized along some index set: time, radius/luminosity, and\nrevisit-count.\nThis format enforces a certain discipline in how a summary should be\ndone: within a bin defined by the index set\n(\"month 15 of the simulation\", \"radius in range X, luminosity in range Y\"),\ncounts that fall in each bin are accumulated across DRMs.\nThen, means, standard errors, and quantiles can be computed from\nthe counts.\nSo, all CSVs have two columns indicating the lower and upper bin\nboundaries, and for each quantity\nof interest, there is one column each for the mean, standard error, and\neach quantile needed.\n\n\nAs an example, the fields now stored in \nreduce_times.csv\n are:\n\n\nh_det_time_lo,             -- bin boundaries\nh_det_time_hi,\nh_det_time_all_mean,   -- cumulative detections\nh_det_time_all_std,\nh_det_time_unq_mean,  -- unique detections only\nh_det_time_unq_std,\nh_det_time_rev_mean,   -- revisits only\nh_det_time_rev_std,\nh_time_fuel_all_mean,   -- fuel use\nh_time_fuel_all_std,\nh_time_fuel_slew_mean,  -- fuel used for slews\nh_time_fuel_slew_std,\nh_time_fuel_keep_mean,  -- fuel for station-keeping\nh_time_fuel_keep_std,\n\n\n\nGraphical Output\n\n\nGraphical outputs are generated by Matlab and by Python.\nIn some ways, Python is preferable, being un-encumbered by licensing\nand more powerful.\nHowever, we are comfortable with Matlab plots, and the reduced\ndata in CSV is easy to load into Matlab, so we adopted a combined approach.\n\n\nGraphical Output Files: Ensemble From Matlab\n\n\nTo make the whole-ensemble\nplots from the CSV files above,\nyou run \nmake graphics\n. \nThis runs a driver (in shell) that invokes Matlab,\nwhich reads the CSVs and invokes plotting m-files for each\nplot flavor (all in \nLocal/Matlab/mfile\n):\n\n\nplot_drms_script.m           -- driver script\nplot_drm_det_times.m      -- detections-vs-time\nplot_drm_fuel_use.m        -- fuel-vs-time\nplot_drm_radlum.m          -- radius/luminosity\nplot_drm_planet_overlay.m   -- sugar for above\nplot_drm_signal_end.m    -- signal success by writing a file\n\n\n\nThe resulting output files are put into files in \n\nsims/\nscript\n/gfx/\n:\n\n\ngfx/det-detects.png\ngfx/det-cume-detects.png\ngfx/det-fuel.png\ngfx/det-radlum-det.png\ngfx/det-radlum-char.png\ngfx/det-radlum-det-all.png\n\n\n\nBoth PNG and PDF are generated.\n\n\nSee the \nbinned ensemble plot gallery\n.\n\n\nGraphical Output Files: Ensemble From Python\n\n\nOther plots show the tour of characterizations\nmade by starshade missions.\nThese are made by the python script\n \nutil/ens-path-graphics.py\n\n which is invoked by \nutil/ens-path-summary.sh\n.\n The \nmake\n target is \npath-ensemble\n. \n\n\nThe resulting output files are put into files in \n\nsims/\nscript\n/path-ens\n:\n\n\npath-map.png                  -- map-format plot of activity\npath-adjacency-lon.png    -- slews, targets ordered by lon \npath-adjacency-lat.png    -- slews, targets ordered by lat\npath-visits.csv                 -- mean number of visits per star\n\n\n\nSee the \nensemble path plot gallery\n. \n\n\nGraphical Output Files: Single DRM\n\n\nSee the \nsingle-drm gallery\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#exosims-sandbox", 
            "text": "We developed an environment for running batches of Exosims simulations.\nThere are three main functional pieces to this sandbox:\nsimulation execution, data reduction, and\ngraphics; also, there is some ancillary support for iPython parallel engines.\nIn general, the workflow is to create an Exosims script, \nrun an ensemble of simulations that dump outputs to disk,\nreduce data from those simulations to\na set of CSV files, and generate plots.  Most of the workflow execution is controlled by a  Makefile , and\nthus invoked by running  make  from the shell with an appropriate target.\nThe components making up this tower of abstraction are described  elsewhere .\nThe  make  mechanism both feeds off of and imposes a file structure,\nwhich we describe next.", 
            "title": "EXOSIMS Sandbox"
        }, 
        {
            "location": "/#sandbox-file-layout", 
            "text": "We run simulations tailored to a couple of mission scenarios.\nWe show HabEx here for example, but the Luvoir simulations have\nthe same layout.  HabEx/\n    README \n    EXOSIMS/          -- symlink to allow \"import EXOSIMS\"\n    Makefile            -- controls execution\n    Scripts/             -- JSON scripts for Exosims\n      .../HabEx_4m.json -- typical input script \n    sims/                -- Ensembles of DRM outputs\n      .../HabEx_4m/...  -- DRMs and data from above script\n    add-sims.sh*    -- adds more Exosims runs to sims/\n    Experiments/    -- groups of ensembles\n       .../HabEx.json  -- Lists selected scripts above\n    exps/                -- results of above\n       .../HabEx/...   --    \n    ipyparallel/       -- ipython parallel configuration\n    util/                  -- generic utility code\n    Local/               -- mission-specific code  The main conventions here are:   The Exosims code applicable to the mission is symlinked so that\nany module can  import EXOSIMS .  The Exosims input scripts are all under the  Scripts  directory.\nAll runs using that script (an  ensemble )\nhave output in the corresponding directory\nunderneath  sims .  For things like parameter sweeps, several related ensembles will\nbe generated for a variety of parameters: we call this an  experiment .\nThe related script names are under  Experiments , and their\ncorresponding output files (graphics) are under  exps .  Most reduction and graphics code lives in  util  and  Local ;\nthe latter is intended to be mission-tailored, but the tailoring\nhas turned out to be minimal.", 
            "title": "Sandbox File Layout"
        }, 
        {
            "location": "/#simulation-output-files", 
            "text": "The subdirectories of  sims  are of particular interest, because they store\nExosims outputs like DRMs, reduced data like CSV files, and graphical\noutputs like plots and movies:  drm/                      -- DRM outputs (time-ordered observation lists)\n    .../seed1.pkl      -- a specific run as a python pickle\n    ...                       -- (and a bunch more runs)\nspc/                       -- SPC (star-planet configuration) files\n    .../seed1.spc        -- a specific SimulatedUniverse as a pickle\n    ...\nrun/                        -- run logs\n    .../outspec.json   -- outspec from given runs\nreduce-info.csv       -- CSV files summarizing the ensemble\nreduce-radlum.csv\nreduce-times.csv\nreduce-visits.csv\nreduce-pool.json\ngfx/                        -- various plots as images\npath/                      -- single-DRM movies\n    .../seed1.mp4\npath-ens/               --  Each Exosims run produces a single DRM, stored in  drm/  according to the\nrandom-number seed, and a corresponding star-planet configuration\n(the  SimulatedUniverse ), stored in  spc/ .\nDepending on how it was run, it may produce a text runlog in  run/ , and\na JSON outspec.  This set of outputs (DRM, SPC, runlog, errorlog, outspec) is made by\na tailored  SurveyEnsemble  class\n( Local/EXOSIMS_local/IPClusterEnsembleJPL2.py ),\nand a shell-level driver and \"run_one\" ( Local/ipcluster_ensemble_jpl_driver.py ).\nThese have been generalized and updated from the Exosims stock.  As mentioned, after an ensemble is run, a reduction script\nis typically invoked that generates the CSV output files,\nand subsequent graphics commands use the ensemble summaries,\nor in some cases just single DRMs.", 
            "title": "Simulation Output Files"
        }, 
        {
            "location": "/#data-reduction", 
            "text": "We separated data reduction from plotting so that reduction of\nthe ensemble could be done once, and then various plots could\nbe remade and tweaked quickly from the reduced data.\nThe python driver is  reduce_drms.py .\nIt contains some re-usable code for loading the ensemble of DRMs\nand for computing summaries (means, standard errors,\nmedians, quantiles, histograms).  Data reduction happens at the ensemble level, by reading in\nthe set of typically ~100 DRMs and corresponding SPCs, and putting\nout the following CSV files.  reduce-info.csv       -- metadata\nreduce-times.csv     -- temporal summaries like fuel use \nreduce-radlum.csv  -- histograms segmented by radius/luminosity\nreduce-visits.csv     -- histograms of revisits\nreduce-earth.csv     -- exo-Earth detection counts\nreduce-pool.json    -- JSON of all reduced data  The CSV format is good at storing vectors, so the above CSV files are\nall vectorized along some index set: time, radius/luminosity, and\nrevisit-count.\nThis format enforces a certain discipline in how a summary should be\ndone: within a bin defined by the index set\n(\"month 15 of the simulation\", \"radius in range X, luminosity in range Y\"),\ncounts that fall in each bin are accumulated across DRMs.\nThen, means, standard errors, and quantiles can be computed from\nthe counts.\nSo, all CSVs have two columns indicating the lower and upper bin\nboundaries, and for each quantity\nof interest, there is one column each for the mean, standard error, and\neach quantile needed.  As an example, the fields now stored in  reduce_times.csv  are:  h_det_time_lo,             -- bin boundaries\nh_det_time_hi,\nh_det_time_all_mean,   -- cumulative detections\nh_det_time_all_std,\nh_det_time_unq_mean,  -- unique detections only\nh_det_time_unq_std,\nh_det_time_rev_mean,   -- revisits only\nh_det_time_rev_std,\nh_time_fuel_all_mean,   -- fuel use\nh_time_fuel_all_std,\nh_time_fuel_slew_mean,  -- fuel used for slews\nh_time_fuel_slew_std,\nh_time_fuel_keep_mean,  -- fuel for station-keeping\nh_time_fuel_keep_std,", 
            "title": "Data Reduction"
        }, 
        {
            "location": "/#graphical-output", 
            "text": "Graphical outputs are generated by Matlab and by Python.\nIn some ways, Python is preferable, being un-encumbered by licensing\nand more powerful.\nHowever, we are comfortable with Matlab plots, and the reduced\ndata in CSV is easy to load into Matlab, so we adopted a combined approach.", 
            "title": "Graphical Output"
        }, 
        {
            "location": "/#graphical-output-files-ensemble-from-matlab", 
            "text": "To make the whole-ensemble\nplots from the CSV files above,\nyou run  make graphics . \nThis runs a driver (in shell) that invokes Matlab,\nwhich reads the CSVs and invokes plotting m-files for each\nplot flavor (all in  Local/Matlab/mfile ):  plot_drms_script.m           -- driver script\nplot_drm_det_times.m      -- detections-vs-time\nplot_drm_fuel_use.m        -- fuel-vs-time\nplot_drm_radlum.m          -- radius/luminosity\nplot_drm_planet_overlay.m   -- sugar for above\nplot_drm_signal_end.m    -- signal success by writing a file  The resulting output files are put into files in  sims/ script /gfx/ :  gfx/det-detects.png\ngfx/det-cume-detects.png\ngfx/det-fuel.png\ngfx/det-radlum-det.png\ngfx/det-radlum-char.png\ngfx/det-radlum-det-all.png  Both PNG and PDF are generated.  See the  binned ensemble plot gallery .", 
            "title": "Graphical Output Files: Ensemble From Matlab"
        }, 
        {
            "location": "/#graphical-output-files-ensemble-from-python", 
            "text": "Other plots show the tour of characterizations\nmade by starshade missions.\nThese are made by the python script\n  util/ens-path-graphics.py \n which is invoked by  util/ens-path-summary.sh .\n The  make  target is  path-ensemble .   The resulting output files are put into files in  sims/ script /path-ens :  path-map.png                  -- map-format plot of activity\npath-adjacency-lon.png    -- slews, targets ordered by lon \npath-adjacency-lat.png    -- slews, targets ordered by lat\npath-visits.csv                 -- mean number of visits per star  See the  ensemble path plot gallery .", 
            "title": "Graphical Output Files: Ensemble From Python"
        }, 
        {
            "location": "/#graphical-output-files-single-drm", 
            "text": "See the  single-drm gallery .", 
            "title": "Graphical Output Files: Single DRM"
        }, 
        {
            "location": "/binned-ensemble-gallery/", 
            "text": "Binned, Ensemble-based Plots\n\n\nThese are the plots we make summarizing an ensemble\nusing compiled histograms.\nDone via CSV files read by Matlab.\n\n\nDetections vs. TIme\n\n\nCumulative detections.\n\n\n\n\n(Full size)\n\n\nDetections within one temporal bin.\n\n\n\n\n(full size)\n\n\nFuel Use vs. TIme\n\n\n\n\n(Full size)\n\n\nRadius/Luminosity Histograms\n\n\nAll detections.\n\n\n\n\n(Full size)\n\n\nUnique detections only.\n\n\n \n\n(Full size)\n \n\n\nCharacterizations.\n\n\n\n\n(Full size)", 
            "title": "Binned Ensemble Galleries"
        }, 
        {
            "location": "/binned-ensemble-gallery/#binned-ensemble-based-plots", 
            "text": "These are the plots we make summarizing an ensemble\nusing compiled histograms.\nDone via CSV files read by Matlab.", 
            "title": "Binned, Ensemble-based Plots"
        }, 
        {
            "location": "/binned-ensemble-gallery/#detections-vs-time", 
            "text": "Cumulative detections.   (Full size)  Detections within one temporal bin.   (full size)", 
            "title": "Detections vs. TIme"
        }, 
        {
            "location": "/binned-ensemble-gallery/#fuel-use-vs-time", 
            "text": "(Full size)", 
            "title": "Fuel Use vs. TIme"
        }, 
        {
            "location": "/binned-ensemble-gallery/#radiusluminosity-histograms", 
            "text": "All detections.   (Full size)  Unique detections only.    (Full size)    Characterizations.   (Full size)", 
            "title": "Radius/Luminosity Histograms"
        }, 
        {
            "location": "/path-ensemble-gallery/", 
            "text": "Ensemble-based Path Plots\n\n\nThese are the plots we make summarizing an entire ensemble of slews.\n\n\nMap-format plot of activity\n\n\n \n\n(Full size)\n \n\n\nSlews with targets ordered by longitude\n\n\n \n\n(Full size)\n \n\n\nSlews with targets ordered by latitude\n\n\n\n\n(Full size)", 
            "title": "Ensemble Path Galleries"
        }, 
        {
            "location": "/path-ensemble-gallery/#ensemble-based-path-plots", 
            "text": "These are the plots we make summarizing an entire ensemble of slews.", 
            "title": "Ensemble-based Path Plots"
        }, 
        {
            "location": "/path-ensemble-gallery/#map-format-plot-of-activity", 
            "text": "(Full size)", 
            "title": "Map-format plot of activity"
        }, 
        {
            "location": "/path-ensemble-gallery/#slews-with-targets-ordered-by-longitude", 
            "text": "(Full size)", 
            "title": "Slews with targets ordered by longitude"
        }, 
        {
            "location": "/path-ensemble-gallery/#slews-with-targets-ordered-by-latitude", 
            "text": "(Full size)", 
            "title": "Slews with targets ordered by latitude"
        }, 
        {
            "location": "/single-drm-gallery/", 
            "text": "Single-DRM Summary\n\n\nWe make a movie summarizing a single DRM: keepout, detections, and characterizations/slews.\nWe also output the final frame of the movie as a still image (PNG), which\nsummarizes\nthe whole DRM.\n\n\nFinal Frame\n\n\n \n\n(Full size)\n \n\n\nMovie\n\n\nFull Movie (mp4)\n\n\nText Summary\n\n\nThe \nutil/drm-ls.py\n routine lists the number of detections in each drm\nnamed.\nSomething like this should be in the Exosims distribution.\n\n\n$ util/drm-ls.py -l sims/HabEx_4m_TS_dmag26p0_20180206f/drm/17*.pkl\nDRM                             Nobs    Ndet    Nchar   Nstar_det\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/170932699.pkl   703 1656    0   237\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/173338520.pkl   653 1529    0   235\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/175677805.pkl   655 1532    0   242\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178486032.pkl   676 1586    0   250\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178752841.pkl   698 1653    0   242\n*TOTAL                          3385    7956    0   1206\n*MEAN                           677.00  1591.20 0.00    241.20\n5 DRMs examined", 
            "title": "Single DRM Galleries"
        }, 
        {
            "location": "/single-drm-gallery/#single-drm-summary", 
            "text": "We make a movie summarizing a single DRM: keepout, detections, and characterizations/slews.\nWe also output the final frame of the movie as a still image (PNG), which\nsummarizes\nthe whole DRM.", 
            "title": "Single-DRM Summary"
        }, 
        {
            "location": "/single-drm-gallery/#final-frame", 
            "text": "(Full size)", 
            "title": "Final Frame"
        }, 
        {
            "location": "/single-drm-gallery/#movie", 
            "text": "Full Movie (mp4)", 
            "title": "Movie"
        }, 
        {
            "location": "/single-drm-gallery/#text-summary", 
            "text": "The  util/drm-ls.py  routine lists the number of detections in each drm\nnamed.\nSomething like this should be in the Exosims distribution.  $ util/drm-ls.py -l sims/HabEx_4m_TS_dmag26p0_20180206f/drm/17*.pkl\nDRM                             Nobs    Ndet    Nchar   Nstar_det\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/170932699.pkl   703 1656    0   237\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/173338520.pkl   653 1529    0   235\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/175677805.pkl   655 1532    0   242\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178486032.pkl   676 1586    0   250\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178752841.pkl   698 1653    0   242\n*TOTAL                          3385    7956    0   1206\n*MEAN                           677.00  1591.20 0.00    241.20\n5 DRMs examined", 
            "title": "Text Summary"
        }, 
        {
            "location": "/execution/", 
            "text": "Pipeline Execution\n\n\nAt the top level, execution is controlled by standard unix \nmake\n.\nThe top-level workflow is as simple as:\n\n\nCreate Scripts/example.json\nmake ipp-start\nadd-sims.sh Scripts/example.json 100 \nmake S=example reduce\nmake S=example graphics\n\n\n\nIf you go away and forget if the graphics are up to date because\nyou might have added more sims, you can just:\n\n\nmake S=example graphics\n\n\n\nand the graphics will be refreshed if there were new simulations added\nsince the last time graphics were made, otherwise, the \nmake\n returns\nimmediately.\nThis is because the graphics target depends on\nthe reduce target, which in turn depends on the \nsims/example\n directory.\nThis is a powerful feature of \nmake\n.\n\n\nTower of abstraction\n\n\nIt's turtles all the way down.\nMake calls a shell-script driver to do reductions and produce graphics.\nTypically the shell-script will enforce the naming conventions\non inputs and outputs, and then call a matlab or python script to do\nthe actual processing.\nSo, there are three levels of abstraction: the make target,\nthe shell driver, and the 'doing' routine, in matlab or python.\n\n\nThe \nMakefile\n lists the targets at the top of the file.\n\n\nAdding simulations to the ensemble\n\n\nAdding simulations is done outside make with the \nadd-sims.sh\n\nshell script driver.\nIts general usage is simply:\n\n\nadd-sims.sh SCRIPT N\n\n\n\nwhere \nSCRIPT\n is the JSON script, and \nN\n is the number of sims\nto add to the ensemble tied to \nSCRIPT\n.\nThis pushes down to a call to our main driver script for\nExosims, \nLocal/ipcluster_ensemble_jpl_driver.py\n.\nThe main function of this driver is to put results (DRM, SPC) in the proper place,\nand to perform logging.\n\n\nTwo options to add-sims are noteworthy:\n\n\n-P PAR    =\n run without ipython parallel, using PAR independent jobs\n-S SEEDS  =\n perform one sim for each integer seed, one per line,\n           in the file SEEDS.  Implies -P.\n\n\n\nThe \n-P\n option uses the same underlying run code, but\nuses independent jobs (run in parallel using \nxargs\n)\nrather than ipyparallel.\n\n\nThe \n-S SEEDS\n option allows multiple ensembles to use the same\nset of seeds, so that yield variability due to parameter changes\nis isolated from that due to the simulated universe.\nOne Exosims simulation is run per seed.\n\n\niPython parallel support\n\n\nWe added some iPython-parallel (\"ipp\") targets to the \nMakefile\n, which you\ninvoke (for example) like:\n\nmake ipp-create\n.\nThe list of targets is as follows:\n\n\n\n\n\n\nipp-create\n: create an ipython-parallel profile for this mission (use once\n     per directory only).\n     Copies several files into the ipyparallel directory.\n     To undo, see \nipp-nuke\n, below.\n\n\n\n\n\n\nipp-start\n: start the ipython-parallel controller and engines\n     Note: If \nEXOSIMS_ENGINE_N\n (an integer) is exported from the environment,\n     this many engines will be started up, otherwise, the system-default\n     will be used.  To use this, run, from the shell:\n\n\n$ EXOSIMS_ENGINE_N=8 make ipp-start\n\n\n\n\n\n\nipp-stop\n: stop the above.  See also \nipp-kill\n, below.\n\n\n\n\n\n\nipp-status\n: report status of the controller and engines\n     Note: This attempts to run trivial jobs on the remote engines, so it\n     will not work if the engines are busy with another job.  See \nipp-ps\n, below.\n\n\n\n\n\n\nipp-ps\n: use the unix \nps\n command to identify the number of running engines\n\n\n\n\n\n\nipp-kill\n: sometimes \nipp-stop\n does not work and engines or controllers\n     are orphaned.  \nipp-kill\n identifies these by process id, and kills them.\n\n\n\n\n\n\nipp-nuke\n: deletes your ipython-parallel profile.  The inverse of \nipp-create\n.\n     (Note: attempts to \nipp-kill\n first, so as to not leave engines running.)\n\n\n\n\n\n\nAs evidenced by the various status and termination commands, sometimes\nusing ipython parallel in this context can be annoying, because you have\nto remember the state of the worker engines.\nIn particular, the engines will have to be restarted (ipp-stop followed by ipp-start)\nwhen the underlying Exosims code changes, because the engines will have a stale copy.", 
            "title": "Execution"
        }, 
        {
            "location": "/execution/#pipeline-execution", 
            "text": "At the top level, execution is controlled by standard unix  make .\nThe top-level workflow is as simple as:  Create Scripts/example.json\nmake ipp-start\nadd-sims.sh Scripts/example.json 100 \nmake S=example reduce\nmake S=example graphics  If you go away and forget if the graphics are up to date because\nyou might have added more sims, you can just:  make S=example graphics  and the graphics will be refreshed if there were new simulations added\nsince the last time graphics were made, otherwise, the  make  returns\nimmediately.\nThis is because the graphics target depends on\nthe reduce target, which in turn depends on the  sims/example  directory.\nThis is a powerful feature of  make .", 
            "title": "Pipeline Execution"
        }, 
        {
            "location": "/execution/#tower-of-abstraction", 
            "text": "It's turtles all the way down.\nMake calls a shell-script driver to do reductions and produce graphics.\nTypically the shell-script will enforce the naming conventions\non inputs and outputs, and then call a matlab or python script to do\nthe actual processing.\nSo, there are three levels of abstraction: the make target,\nthe shell driver, and the 'doing' routine, in matlab or python.  The  Makefile  lists the targets at the top of the file.", 
            "title": "Tower of abstraction"
        }, 
        {
            "location": "/execution/#adding-simulations-to-the-ensemble", 
            "text": "Adding simulations is done outside make with the  add-sims.sh \nshell script driver.\nIts general usage is simply:  add-sims.sh SCRIPT N  where  SCRIPT  is the JSON script, and  N  is the number of sims\nto add to the ensemble tied to  SCRIPT .\nThis pushes down to a call to our main driver script for\nExosims,  Local/ipcluster_ensemble_jpl_driver.py .\nThe main function of this driver is to put results (DRM, SPC) in the proper place,\nand to perform logging.  Two options to add-sims are noteworthy:  -P PAR    =  run without ipython parallel, using PAR independent jobs\n-S SEEDS  =  perform one sim for each integer seed, one per line,\n           in the file SEEDS.  Implies -P.  The  -P  option uses the same underlying run code, but\nuses independent jobs (run in parallel using  xargs )\nrather than ipyparallel.  The  -S SEEDS  option allows multiple ensembles to use the same\nset of seeds, so that yield variability due to parameter changes\nis isolated from that due to the simulated universe.\nOne Exosims simulation is run per seed.", 
            "title": "Adding simulations to the ensemble"
        }, 
        {
            "location": "/execution/#ipython-parallel-support", 
            "text": "We added some iPython-parallel (\"ipp\") targets to the  Makefile , which you\ninvoke (for example) like: make ipp-create .\nThe list of targets is as follows:    ipp-create : create an ipython-parallel profile for this mission (use once\n     per directory only).\n     Copies several files into the ipyparallel directory.\n     To undo, see  ipp-nuke , below.    ipp-start : start the ipython-parallel controller and engines\n     Note: If  EXOSIMS_ENGINE_N  (an integer) is exported from the environment,\n     this many engines will be started up, otherwise, the system-default\n     will be used.  To use this, run, from the shell:  $ EXOSIMS_ENGINE_N=8 make ipp-start    ipp-stop : stop the above.  See also  ipp-kill , below.    ipp-status : report status of the controller and engines\n     Note: This attempts to run trivial jobs on the remote engines, so it\n     will not work if the engines are busy with another job.  See  ipp-ps , below.    ipp-ps : use the unix  ps  command to identify the number of running engines    ipp-kill : sometimes  ipp-stop  does not work and engines or controllers\n     are orphaned.   ipp-kill  identifies these by process id, and kills them.    ipp-nuke : deletes your ipython-parallel profile.  The inverse of  ipp-create .\n     (Note: attempts to  ipp-kill  first, so as to not leave engines running.)    As evidenced by the various status and termination commands, sometimes\nusing ipython parallel in this context can be annoying, because you have\nto remember the state of the worker engines.\nIn particular, the engines will have to be restarted (ipp-stop followed by ipp-start)\nwhen the underlying Exosims code changes, because the engines will have a stale copy.", 
            "title": "iPython parallel support"
        }
    ]
}