{
    "docs": [
        {
            "location": "/", 
            "text": "EXOSIMS Sandbox\n\n\nWe developed an environment for running batches of Exosims simulations.\nThere are four main functional pieces to this sandbox:\nsimulation execution, data reduction, \ngraphics generation, and webpage generation.\nAlso, there is some ancillary support for\nensembles of related simulations for parameter-tuning, \niPython parallel engines, and a webserver for inspection of results.\nIn general, the workflow is to create an Exosims script, \nrun an ensemble of simulations that dump outputs to disk,\nreduce data from those simulations to\na set of CSV files, and generate plots.\n\n\nMost of the workflow execution is controlled by a \nMakefile\n, and\nthus invoked by running \nmake\n from the shell with an appropriate target.\nThe components making up this tower of abstraction are described \nelsewhere\n.\nThe \nmake\n mechanism both feeds off of and imposes a file structure,\nwhich we describe next.\n\n\nSandbox File Layout\n\n\nWe run simulations tailored to a couple of mission scenarios.\nWe show HabEx here for example, but the Luvoir simulations have\nthe same layout.\n\n\nHabEx/\n    README \n    EXOSIMS/          -- symlink to allow \"import EXOSIMS\"\n    Makefile            -- controls execution\n    Scripts/             -- JSON scripts for Exosims\n      .../HabEx_4m.json -- typical input script \n    sims/                -- Ensembles of DRM outputs\n      .../HabEx_4m/...  -- DRMs and data from above script\n    add-sims.sh     -- adds more Exosims runs to sims/\n    Experiments/    -- groups of ensembles\n       .../HabEx.json  -- Lists selected scripts above\n    ipyparallel/       -- ipython parallel configuration, per-user\n    util/                  -- mission-generic utility code\n    Local/               -- mission-specific code\n\n\n\nThe main conventions here are:\n\n\n\n\nThe Exosims code applicable to the mission is symlinked so that\nany module here can \nimport EXOSIMS\n successfully.\n\n\nThe Exosims input scripts are all under the \nScripts\n directory.\nAll runs using that script (an \nensemble\n)\nhave output in the corresponding directory\nunderneath \nsims\n.\nThis convention allows all utilities to place reduced data, graphics,\nand html index pages into standard locations.\n\n\nFor things like parameter sweeps, several related ensembles will\nbe generated for a variety of parameters.  We call this an \nexperiment\n.\nThe Exosims input scripts pertaining to an experiment\nare generated from templates that are filed\nunder \nExperiments\n. Their\ncorresponding output files (graphics) are also in directories \nunder \nsims\n, but nested one level down.\nThat is, scripts for an experiment named \"Tune\" will be in files\n\nScripts/Tune.exp/PARAM.json\n, and the simulation results will\nbe in files like \nsims/Tune.exp/PARAM/...\n.\nThe \nMakefile\n has targets pertaining to such experiments.\n\n\nMost reduction and graphics code lives in \nutil\n and \nLocal\n;\nthe latter is intended to be mission-tailored, but the tailoring\nhas turned out to be minimal.\n\n\n\n\nSimulation Output Files\n\n\nThe subdirectories of \nsims\n are of particular interest, because they store\nExosims outputs like DRMs, reduced data like CSV files, and graphical\noutputs like plots and movies:\n\n\ndrm/                      -- DRM outputs (time-ordered observation lists)\n    .../seed1.pkl      -- a specific run as a python pickle\n    ...                       -- (and a bunch more runs)\nspc/                       -- SPC (star-planet configuration) files\n    .../seed1.spc        -- a specific SimulatedUniverse as a pickle\n    ...\nrun/                        -- run logs\n    .../outspec.json   -- outspec from given runs\nreduce-info.csv       -- CSV files summarizing the ensemble\nreduce-radlum.csv\nreduce-times.csv\nreduce-visits.csv, etc.\nreduce-pool.json\ngfx/                        -- various plots as images\npath/                      -- single-DRM movies\n    .../seed1.mp4\npath-ens/               --\n\n\n\nEach Exosims run produces a single DRM, stored in \ndrm/\n according to the\nrandom-number seed, and a corresponding star-planet configuration\n(the \nSimulatedUniverse\n), stored in \nspc/\n.\nDepending on how it was run, it may produce a text runlog in \nlog/\n, and\na JSON outspec in \nrun/\n.\n\n\nThis set of outputs (DRM, SPC, runlog, errorlog, outspec) is made by\na tailored \nSurveyEnsemble\n class\n(\nLocal/EXOSIMS_local/IPClusterEnsembleJPL2.py\n),\nand a shell-level driver and \"run_one\" (\nLocal/ipcluster_ensemble_jpl_driver.py\n).\nThese have been generalized and updated from the Exosims standard files,\nwhich are documented in Exosims as subclasses following the\n\nSurveyEnsemble\n prototype.\n\n\nAs mentioned, after an ensemble is run, a reduction script\nis typically invoked that generates the CSV output files,\nand subsequent graphics commands use the ensemble summaries,\nor in some cases just single DRMs.\n\n\nData Reduction\n\n\nWe separated data reduction from plotting so that reduction of\nthe ensemble could be done once, and then various plots could\nbe remade and tweaked quickly from the reduced data.\nThe python driver is \nreduce_drms.py\n.\nIt contains some re-usable code for loading the ensemble of DRMs\nand for computing summaries (means, standard errors,\nmedians, quantiles, histograms).\nWith only one exception, \nreduce_drms\n produces averages over\nthe ensemble.  Note that this does not limit us to mean values!\nFor example, a histogram of yields is also an average over the ensemble:\nbin number \"N\" of a yield histogram\ncontains the average, across the ensemble,\nof this 0/1 variable: \"N\" exo-earths were detected in the simulation.\n\n\nData reduction happens at the ensemble level, by reading in\nthe set of typically ~100 DRMs and corresponding SPCs, and putting\nout CSV files such as the following non-exclusive list:\n\n\nreduce-info.csv       -- metadata\nreduce-times.csv     -- temporal summaries like fuel use \nreduce-radlum.csv  -- histograms segmented by radius/luminosity\nreduce-visits.csv     -- histograms of revisits\nreduce-earth.csv     -- exo-Earth detection counts\n\n\n\nCurrently, there are 14 such files.\n\n\nThe CSV format is good at storing vectors, so the above CSV files are\nall vectorized along some index set: time, radius/luminosity, or \nrevisit-count.\nThis format enforces a certain discipline in how a summary should be\ndone: within a bin defined by the index set\n(\"month 15 of the simulation\", \"radius in range X, luminosity in range Y\"),\ncounts that fall in each bin are accumulated across DRMs.\nThen, means, standard errors, and quantiles can be computed from\nthe counts.\nSo, all CSVs have two columns indicating the lower and upper bin\nboundaries, and for each quantity\nof interest, there is one column each for the mean, standard error, \neach quantile needed, and the number of ensemble members comprising\nthat mean.\n\n\nAs an example, the fields now stored in \nreduce_times.csv\n include:\n\n\nh_det_time_lo,             -- bin boundaries\nh_det_time_hi,\nh_det_time_all_mean,   -- cumulative detections\nh_det_time_all_std, \nh_det_time_all_nEns, \nh_det_time_unq_mean,  -- unique detections only\nh_det_time_unq_std, \nh_det_time_unq_nEns, \nh_det_time_rev_mean,   -- revisits only\nh_det_time_rev_std, \nh_det_time_rev_nEns, \nh_time_fuel_all_mean,   -- fuel use\nh_time_fuel_all_std, \nh_time_fuel_all_nEns, \nh_time_fuel_slew_mean,  -- fuel used for slews\nh_time_fuel_slew_std, \nh_time_fuel_slew_nEns, \nh_time_fuel_keep_mean,  -- fuel for station-keeping\nh_time_fuel_keep_std, \nh_time_fuel_keep_nEns\n\n\n\nThere are 89 such fields in that file, and about 1100 summarized quantities\nall together.\n\n\nThe one exception to this is the file \nreduce-earth-char-list.csv\n, which\nsimply contains a list of all attempted characterizations across the entire ensemble.\n\n\nGraphical Output\n\n\nGraphical outputs are generated by Matlab and by Python.\nIn some ways, Python is preferable, being un-encumbered by licensing\nand more powerful.\nHowever, we are comfortable with Matlab plots, and the reduced\ndata in CSV is easy to load into Matlab, so we adopted a combined approach.\n\n\nGraphical Output Files: Ensemble From Matlab\n\n\nTo make the whole-ensemble\nplots from the CSV files above,\nyou run \nmake S=(SCRIPT) graphics\n. \nThis runs a driver (in the shell) that invokes Matlab,\nwhich reads the CSVs and invokes plotting m-files\n(all in \nLocal/Matlab/mfile\n) for each\nplot flavor, including for example:\n\n\nplot_drms_script.m           -- driver script\nplot_drm_det_times.m      -- detections-vs-time\nplot_drm_fuel_use.m        -- fuel-vs-time\nplot_drm_radlum.m          -- radius/luminosity\nplot_drm_signal_end.m    -- signals success by writing a file\n\n\n\nThe resulting output files are put into files like the following in \n\nsims/\nscript\n/gfx/\n:\n\n\ngfx/det-detects.png\ngfx/det-cume-detects.png\ngfx/det-fuel.png\ngfx/det-radlum-det.png\ngfx/det-radlum-char.png\ngfx/det-radlum-det-all.png\n\n\n\nCurrently, 90 files are generated, mostly PNG image files, but also some PDF files.\n\n\nSee the \nbinned ensemble plot gallery\n.\n\n\nGraphical Output Files: Ensemble From Python\n\n\nOther plots show the tour of characterizations\nmade by starshade missions.\nThese are made by the python script\n \nutil/ens-path-graphics.py\n\n which is invoked by \nutil/ens-path-summary.sh\n.\n The \nmake\n target is \npath-ensemble\n. \n\n\nThe resulting output files are put into files in \n\nsims/\nscript\n/path-ens\n:\n\n\npath-map.png                  -- map-format plot of activity\npath-adjacency-lon.png    -- slews, targets ordered by lon \npath-adjacency-lat.png    -- slews, targets ordered by lat\npath-visits.csv                 -- mean number of visits per star \npath-slews.csv                 -- total slews between pairs of stars\n\n\n\nSee the \nensemble path plot gallery\n.\n\n\nThe latter two CSV files are used by a javascript widget in the generated HTML\npage to show a zoomable plot of slews across the ensemble.\n\n\nGraphical Output Files: Single DRM\n\n\nA final set of plots shows the observations, keepout, or slews for a single\nDRM.\nThey are useful in analyzing observation-scheduling behavior, \nverifying that keepout constraints are honored, and related questions.\nThey are made by \nplot-keepout-and-obs.py\n, \nplot-timeline.py\n,\nand \nkeepout_path_graphics.py\n.\n\n\nFor a given DRM with a certain (integer) SEED,\nthese files are placed in the directory\n\nsims/\nscript\n/path/\n, and named like:\n\n\nSEED-obs-timeline.png  -- time-format plot of all observations\nSEED-obs-keepout-all.png -- time-format plot of keepout (all obs.)\nSEED-obs-keepout-char.png -- time-format plot of keepout (char only)\nSEED-obs-timeline-info.csv\nSEED.mp4 -- movie of all detection and char observations\nSEED-final.png -- final frame of above movie\n\n\n\nSome other plots and summaries are placed in the directory\n\nsims/\nscript\n/path/SEED-cume\n, including:\n\n\npath-visits.csv\npath-slews.csv\n\n\n\nwhich are used by the same javascript widget described above, to\nshow a zoomable plot of slews for just that DRM.\n\n\nSee the \nsingle-drm gallery\n.", 
            "title": "Home"
        }, 
        {
            "location": "/#exosims-sandbox", 
            "text": "We developed an environment for running batches of Exosims simulations.\nThere are four main functional pieces to this sandbox:\nsimulation execution, data reduction, \ngraphics generation, and webpage generation.\nAlso, there is some ancillary support for\nensembles of related simulations for parameter-tuning, \niPython parallel engines, and a webserver for inspection of results.\nIn general, the workflow is to create an Exosims script, \nrun an ensemble of simulations that dump outputs to disk,\nreduce data from those simulations to\na set of CSV files, and generate plots.  Most of the workflow execution is controlled by a  Makefile , and\nthus invoked by running  make  from the shell with an appropriate target.\nThe components making up this tower of abstraction are described  elsewhere .\nThe  make  mechanism both feeds off of and imposes a file structure,\nwhich we describe next.", 
            "title": "EXOSIMS Sandbox"
        }, 
        {
            "location": "/#sandbox-file-layout", 
            "text": "We run simulations tailored to a couple of mission scenarios.\nWe show HabEx here for example, but the Luvoir simulations have\nthe same layout.  HabEx/\n    README \n    EXOSIMS/          -- symlink to allow \"import EXOSIMS\"\n    Makefile            -- controls execution\n    Scripts/             -- JSON scripts for Exosims\n      .../HabEx_4m.json -- typical input script \n    sims/                -- Ensembles of DRM outputs\n      .../HabEx_4m/...  -- DRMs and data from above script\n    add-sims.sh     -- adds more Exosims runs to sims/\n    Experiments/    -- groups of ensembles\n       .../HabEx.json  -- Lists selected scripts above\n    ipyparallel/       -- ipython parallel configuration, per-user\n    util/                  -- mission-generic utility code\n    Local/               -- mission-specific code  The main conventions here are:   The Exosims code applicable to the mission is symlinked so that\nany module here can  import EXOSIMS  successfully.  The Exosims input scripts are all under the  Scripts  directory.\nAll runs using that script (an  ensemble )\nhave output in the corresponding directory\nunderneath  sims .\nThis convention allows all utilities to place reduced data, graphics,\nand html index pages into standard locations.  For things like parameter sweeps, several related ensembles will\nbe generated for a variety of parameters.  We call this an  experiment .\nThe Exosims input scripts pertaining to an experiment\nare generated from templates that are filed\nunder  Experiments . Their\ncorresponding output files (graphics) are also in directories \nunder  sims , but nested one level down.\nThat is, scripts for an experiment named \"Tune\" will be in files Scripts/Tune.exp/PARAM.json , and the simulation results will\nbe in files like  sims/Tune.exp/PARAM/... .\nThe  Makefile  has targets pertaining to such experiments.  Most reduction and graphics code lives in  util  and  Local ;\nthe latter is intended to be mission-tailored, but the tailoring\nhas turned out to be minimal.", 
            "title": "Sandbox File Layout"
        }, 
        {
            "location": "/#simulation-output-files", 
            "text": "The subdirectories of  sims  are of particular interest, because they store\nExosims outputs like DRMs, reduced data like CSV files, and graphical\noutputs like plots and movies:  drm/                      -- DRM outputs (time-ordered observation lists)\n    .../seed1.pkl      -- a specific run as a python pickle\n    ...                       -- (and a bunch more runs)\nspc/                       -- SPC (star-planet configuration) files\n    .../seed1.spc        -- a specific SimulatedUniverse as a pickle\n    ...\nrun/                        -- run logs\n    .../outspec.json   -- outspec from given runs\nreduce-info.csv       -- CSV files summarizing the ensemble\nreduce-radlum.csv\nreduce-times.csv\nreduce-visits.csv, etc.\nreduce-pool.json\ngfx/                        -- various plots as images\npath/                      -- single-DRM movies\n    .../seed1.mp4\npath-ens/               --  Each Exosims run produces a single DRM, stored in  drm/  according to the\nrandom-number seed, and a corresponding star-planet configuration\n(the  SimulatedUniverse ), stored in  spc/ .\nDepending on how it was run, it may produce a text runlog in  log/ , and\na JSON outspec in  run/ .  This set of outputs (DRM, SPC, runlog, errorlog, outspec) is made by\na tailored  SurveyEnsemble  class\n( Local/EXOSIMS_local/IPClusterEnsembleJPL2.py ),\nand a shell-level driver and \"run_one\" ( Local/ipcluster_ensemble_jpl_driver.py ).\nThese have been generalized and updated from the Exosims standard files,\nwhich are documented in Exosims as subclasses following the SurveyEnsemble  prototype.  As mentioned, after an ensemble is run, a reduction script\nis typically invoked that generates the CSV output files,\nand subsequent graphics commands use the ensemble summaries,\nor in some cases just single DRMs.", 
            "title": "Simulation Output Files"
        }, 
        {
            "location": "/#data-reduction", 
            "text": "We separated data reduction from plotting so that reduction of\nthe ensemble could be done once, and then various plots could\nbe remade and tweaked quickly from the reduced data.\nThe python driver is  reduce_drms.py .\nIt contains some re-usable code for loading the ensemble of DRMs\nand for computing summaries (means, standard errors,\nmedians, quantiles, histograms).\nWith only one exception,  reduce_drms  produces averages over\nthe ensemble.  Note that this does not limit us to mean values!\nFor example, a histogram of yields is also an average over the ensemble:\nbin number \"N\" of a yield histogram\ncontains the average, across the ensemble,\nof this 0/1 variable: \"N\" exo-earths were detected in the simulation.  Data reduction happens at the ensemble level, by reading in\nthe set of typically ~100 DRMs and corresponding SPCs, and putting\nout CSV files such as the following non-exclusive list:  reduce-info.csv       -- metadata\nreduce-times.csv     -- temporal summaries like fuel use \nreduce-radlum.csv  -- histograms segmented by radius/luminosity\nreduce-visits.csv     -- histograms of revisits\nreduce-earth.csv     -- exo-Earth detection counts  Currently, there are 14 such files.  The CSV format is good at storing vectors, so the above CSV files are\nall vectorized along some index set: time, radius/luminosity, or \nrevisit-count.\nThis format enforces a certain discipline in how a summary should be\ndone: within a bin defined by the index set\n(\"month 15 of the simulation\", \"radius in range X, luminosity in range Y\"),\ncounts that fall in each bin are accumulated across DRMs.\nThen, means, standard errors, and quantiles can be computed from\nthe counts.\nSo, all CSVs have two columns indicating the lower and upper bin\nboundaries, and for each quantity\nof interest, there is one column each for the mean, standard error, \neach quantile needed, and the number of ensemble members comprising\nthat mean.  As an example, the fields now stored in  reduce_times.csv  include:  h_det_time_lo,             -- bin boundaries\nh_det_time_hi,\nh_det_time_all_mean,   -- cumulative detections\nh_det_time_all_std, \nh_det_time_all_nEns, \nh_det_time_unq_mean,  -- unique detections only\nh_det_time_unq_std, \nh_det_time_unq_nEns, \nh_det_time_rev_mean,   -- revisits only\nh_det_time_rev_std, \nh_det_time_rev_nEns, \nh_time_fuel_all_mean,   -- fuel use\nh_time_fuel_all_std, \nh_time_fuel_all_nEns, \nh_time_fuel_slew_mean,  -- fuel used for slews\nh_time_fuel_slew_std, \nh_time_fuel_slew_nEns, \nh_time_fuel_keep_mean,  -- fuel for station-keeping\nh_time_fuel_keep_std, \nh_time_fuel_keep_nEns  There are 89 such fields in that file, and about 1100 summarized quantities\nall together.  The one exception to this is the file  reduce-earth-char-list.csv , which\nsimply contains a list of all attempted characterizations across the entire ensemble.", 
            "title": "Data Reduction"
        }, 
        {
            "location": "/#graphical-output", 
            "text": "Graphical outputs are generated by Matlab and by Python.\nIn some ways, Python is preferable, being un-encumbered by licensing\nand more powerful.\nHowever, we are comfortable with Matlab plots, and the reduced\ndata in CSV is easy to load into Matlab, so we adopted a combined approach.", 
            "title": "Graphical Output"
        }, 
        {
            "location": "/#graphical-output-files-ensemble-from-matlab", 
            "text": "To make the whole-ensemble\nplots from the CSV files above,\nyou run  make S=(SCRIPT) graphics . \nThis runs a driver (in the shell) that invokes Matlab,\nwhich reads the CSVs and invokes plotting m-files\n(all in  Local/Matlab/mfile ) for each\nplot flavor, including for example:  plot_drms_script.m           -- driver script\nplot_drm_det_times.m      -- detections-vs-time\nplot_drm_fuel_use.m        -- fuel-vs-time\nplot_drm_radlum.m          -- radius/luminosity\nplot_drm_signal_end.m    -- signals success by writing a file  The resulting output files are put into files like the following in  sims/ script /gfx/ :  gfx/det-detects.png\ngfx/det-cume-detects.png\ngfx/det-fuel.png\ngfx/det-radlum-det.png\ngfx/det-radlum-char.png\ngfx/det-radlum-det-all.png  Currently, 90 files are generated, mostly PNG image files, but also some PDF files.  See the  binned ensemble plot gallery .", 
            "title": "Graphical Output Files: Ensemble From Matlab"
        }, 
        {
            "location": "/#graphical-output-files-ensemble-from-python", 
            "text": "Other plots show the tour of characterizations\nmade by starshade missions.\nThese are made by the python script\n  util/ens-path-graphics.py \n which is invoked by  util/ens-path-summary.sh .\n The  make  target is  path-ensemble .   The resulting output files are put into files in  sims/ script /path-ens :  path-map.png                  -- map-format plot of activity\npath-adjacency-lon.png    -- slews, targets ordered by lon \npath-adjacency-lat.png    -- slews, targets ordered by lat\npath-visits.csv                 -- mean number of visits per star \npath-slews.csv                 -- total slews between pairs of stars  See the  ensemble path plot gallery .  The latter two CSV files are used by a javascript widget in the generated HTML\npage to show a zoomable plot of slews across the ensemble.", 
            "title": "Graphical Output Files: Ensemble From Python"
        }, 
        {
            "location": "/#graphical-output-files-single-drm", 
            "text": "A final set of plots shows the observations, keepout, or slews for a single\nDRM.\nThey are useful in analyzing observation-scheduling behavior, \nverifying that keepout constraints are honored, and related questions.\nThey are made by  plot-keepout-and-obs.py ,  plot-timeline.py ,\nand  keepout_path_graphics.py .  For a given DRM with a certain (integer) SEED,\nthese files are placed in the directory sims/ script /path/ , and named like:  SEED-obs-timeline.png  -- time-format plot of all observations\nSEED-obs-keepout-all.png -- time-format plot of keepout (all obs.)\nSEED-obs-keepout-char.png -- time-format plot of keepout (char only)\nSEED-obs-timeline-info.csv\nSEED.mp4 -- movie of all detection and char observations\nSEED-final.png -- final frame of above movie  Some other plots and summaries are placed in the directory sims/ script /path/SEED-cume , including:  path-visits.csv\npath-slews.csv  which are used by the same javascript widget described above, to\nshow a zoomable plot of slews for just that DRM.  See the  single-drm gallery .", 
            "title": "Graphical Output Files: Single DRM"
        }, 
        {
            "location": "/binned-ensemble-gallery/", 
            "text": "Binned, Ensemble-based Plots\n\n\nThese are the plots we make summarizing an ensemble\nusing compiled histograms.\nDone via CSV files read by Matlab.\n\n\nDetections vs. TIme\n\n\nCumulative detections.\n\n\n\n\n(Full size)\n\n\nDetections within one temporal bin.\n\n\n\n\n(full size)\n\n\nFuel Use vs. TIme\n\n\n\n\n(Full size)\n\n\nRadius/Luminosity Histograms\n\n\nAll detections.\n\n\n\n\n(Full size)\n\n\nUnique detections only.\n\n\n \n\n(Full size)\n \n\n\nCharacterizations.\n\n\n\n\n(Full size)", 
            "title": "Binned Ensemble Galleries"
        }, 
        {
            "location": "/binned-ensemble-gallery/#binned-ensemble-based-plots", 
            "text": "These are the plots we make summarizing an ensemble\nusing compiled histograms.\nDone via CSV files read by Matlab.", 
            "title": "Binned, Ensemble-based Plots"
        }, 
        {
            "location": "/binned-ensemble-gallery/#detections-vs-time", 
            "text": "Cumulative detections.   (Full size)  Detections within one temporal bin.   (full size)", 
            "title": "Detections vs. TIme"
        }, 
        {
            "location": "/binned-ensemble-gallery/#fuel-use-vs-time", 
            "text": "(Full size)", 
            "title": "Fuel Use vs. TIme"
        }, 
        {
            "location": "/binned-ensemble-gallery/#radiusluminosity-histograms", 
            "text": "All detections.   (Full size)  Unique detections only.    (Full size)    Characterizations.   (Full size)", 
            "title": "Radius/Luminosity Histograms"
        }, 
        {
            "location": "/path-ensemble-gallery/", 
            "text": "Ensemble-based Path Plots\n\n\nThese are the plots we make summarizing an entire ensemble of slews.\n\n\nMap-format plot of activity\n\n\n \n\n(Full size)\n \n\n\nSlews with targets ordered by longitude\n\n\n \n\n(Full size)\n \n\n\nSlews with targets ordered by latitude\n\n\n\n\n(Full size)", 
            "title": "Ensemble Path Galleries"
        }, 
        {
            "location": "/path-ensemble-gallery/#ensemble-based-path-plots", 
            "text": "These are the plots we make summarizing an entire ensemble of slews.", 
            "title": "Ensemble-based Path Plots"
        }, 
        {
            "location": "/path-ensemble-gallery/#map-format-plot-of-activity", 
            "text": "(Full size)", 
            "title": "Map-format plot of activity"
        }, 
        {
            "location": "/path-ensemble-gallery/#slews-with-targets-ordered-by-longitude", 
            "text": "(Full size)", 
            "title": "Slews with targets ordered by longitude"
        }, 
        {
            "location": "/path-ensemble-gallery/#slews-with-targets-ordered-by-latitude", 
            "text": "(Full size)", 
            "title": "Slews with targets ordered by latitude"
        }, 
        {
            "location": "/single-drm-gallery/", 
            "text": "Single-DRM Summary\n\n\nWe make a movie summarizing a single DRM: keepout, detections, and characterizations/slews.\nWe also output the final frame of the movie as a still image (PNG), which\nsummarizes\nthe whole DRM.\n\n\nFinal Frame\n\n\n \n\n(Full size)\n \n\n\nMovie\n\n\nFull Movie (mp4)\n\n\nText Summary\n\n\nThe \nutil/drm-ls.py\n routine lists the number of detections in each drm\nnamed.\nSomething like this should be in the Exosims distribution.\n\n\n$ util/drm-ls.py -l sims/HabEx_4m_TS_dmag26p0_20180206f/drm/17*.pkl\nDRM                             Nobs    Ndet    Nchar   Nstar_det\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/170932699.pkl   703 1656    0   237\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/173338520.pkl   653 1529    0   235\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/175677805.pkl   655 1532    0   242\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178486032.pkl   676 1586    0   250\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178752841.pkl   698 1653    0   242\n*TOTAL                          3385    7956    0   1206\n*MEAN                           677.00  1591.20 0.00    241.20\n5 DRMs examined", 
            "title": "Single DRM Galleries"
        }, 
        {
            "location": "/single-drm-gallery/#single-drm-summary", 
            "text": "We make a movie summarizing a single DRM: keepout, detections, and characterizations/slews.\nWe also output the final frame of the movie as a still image (PNG), which\nsummarizes\nthe whole DRM.", 
            "title": "Single-DRM Summary"
        }, 
        {
            "location": "/single-drm-gallery/#final-frame", 
            "text": "(Full size)", 
            "title": "Final Frame"
        }, 
        {
            "location": "/single-drm-gallery/#movie", 
            "text": "Full Movie (mp4)", 
            "title": "Movie"
        }, 
        {
            "location": "/single-drm-gallery/#text-summary", 
            "text": "The  util/drm-ls.py  routine lists the number of detections in each drm\nnamed.\nSomething like this should be in the Exosims distribution.  $ util/drm-ls.py -l sims/HabEx_4m_TS_dmag26p0_20180206f/drm/17*.pkl\nDRM                             Nobs    Ndet    Nchar   Nstar_det\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/170932699.pkl   703 1656    0   237\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/173338520.pkl   653 1529    0   235\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/175677805.pkl   655 1532    0   242\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178486032.pkl   676 1586    0   250\nsims/HabEx_4m_TS_dmag26p0_20180206f/drm/178752841.pkl   698 1653    0   242\n*TOTAL                          3385    7956    0   1206\n*MEAN                           677.00  1591.20 0.00    241.20\n5 DRMs examined", 
            "title": "Text Summary"
        }, 
        {
            "location": "/execution/", 
            "text": "Pipeline Execution\n\n\nAt the top level, execution is controlled by standard unix \nmake\n.\nThe top-level workflow is as simple as:\n\n\nCreate Scripts/example.json\nmake ipp-start\nadd-sims.sh Scripts/example.json 100 \nmake S=example reduce\nmake S=example graphics\n\n\n\nIf you go away and forget if the graphics are up to date because\nyou might have added more sims, you can just:\n\n\nmake S=example graphics\n\n\n\nand the graphics will be refreshed if there were new simulations added\nsince the last time graphics were made, otherwise, the \nmake\n returns\nimmediately.\nThis is because the graphics target depends on\nthe reduce target, which in turn depends on the \nsims/example\n directory.\nThis is a powerful feature of \nmake\n.\n\n\nThis works automatically when downstream data needs to change in\nresponse to additional upstream data.\nIf the underlying graphics code changes (\"titles in 14 point\") you\nneed to force the graphics refresh by supplying \n-B\n to \nmake\n,\nwhich forces the rebuild:\n\n\nmake -B S=example graphics\n\n\n\nTower of abstraction\n\n\nIt's turtles (of varying colors) all the way down.\nMake calls a shell-script driver to do reductions and produce graphics.\nTypically the shell-script will enforce the naming conventions\non inputs and outputs, and then call a matlab or python script to do\nthe actual processing.\nSo, there are three levels of abstraction: the make target,\nthe shell driver, and the 'doing' routine, in matlab or python.\n\n\nThe \nMakefile\n lists the targets at the top of the file.\n\n\nAdding simulations to the ensemble\n\n\nAdding simulations is done outside make with the \nadd-sims.sh\n\nshell script driver.\nIts general usage is simply:\n\n\nadd-sims.sh SCRIPT N\n\n\n\nwhere \nSCRIPT\n is the JSON script, and \nN\n is the number of sims\nto add to the ensemble tied to \nSCRIPT\n.\nThis pushes down to a call to our main driver script for\nExosims, \nLocal/ipcluster_ensemble_jpl_driver.py\n.\nThe main function of this driver is to put results (DRM, SPC) in the proper place,\nand to perform logging.\n\n\nTwo options to add-sims are noteworthy:\n\n\n-P PAR    =\n run without ipython parallel, using PAR independent jobs\n-S SEEDS  =\n perform one sim for each integer seed, one per line,\n           in the file SEEDS.  Implies -P.\n\n\n\nThe \n-P\n option uses the same underlying run code, but\nuses independent jobs (run in parallel using \nxargs\n)\nrather than ipyparallel.\n\n\nThe \n-S SEEDS\n option allows multiple ensembles to use the same\nset of seeds, so that yield variability due to parameter changes\nis isolated from that due to the simulated universe.\nOne Exosims simulation is run per seed.\n\n\niPython parallel support\n\n\nWe added some iPython-parallel (\"ipp\") targets to the \nMakefile\n, which you\ninvoke (for example) like:\n\nmake ipp-create\n.\nThe list of targets is as follows:\n\n\n\n\n\n\nipp-create\n: create an ipython-parallel profile for this mission (use once\n     per directory only).\n     Copies several files into the ipyparallel directory.\n     To undo, see \nipp-nuke\n, below.\n\n\n\n\n\n\nipp-start\n: start the ipython-parallel controller and engines\n     Note: If \nEXOSIMS_ENGINE_N\n (an integer) is exported from the environment,\n     this many engines will be started up, otherwise, the system-default\n     will be used.  To use this, run, from the shell:\n\n\n$ EXOSIMS_ENGINE_N=8 make ipp-start\n\n\n\n\n\n\nipp-stop\n: stop the above.  See also \nipp-kill\n, below.\n\n\n\n\n\n\nipp-status\n: report status of the controller and engines\n     Note: This attempts to run trivial jobs on the remote engines, so it\n     will not work if the engines are busy with another job.  See \nipp-ps\n, below.\n\n\n\n\n\n\nipp-ps\n: use the unix \nps\n command to identify the number of running engines\n\n\n\n\n\n\nipp-kill\n: sometimes \nipp-stop\n does not work and engines or controllers\n     are orphaned.  \nipp-kill\n identifies these by process id, and kills them.\n\n\n\n\n\n\nipp-nuke\n: deletes your ipython-parallel profile.  The inverse of \nipp-create\n.\n     (Note: attempts to \nipp-kill\n first, so as to not leave engines running.)\n\n\n\n\n\n\nAs evidenced by the various status and termination commands, sometimes\nusing ipython parallel in this context can be annoying, because you have\nto remember the state of the worker engines.\nIn particular, the engines will have to be restarted (ipp-stop followed by ipp-start)\nwhen the underlying Exosims code changes, because the engines will have a stale copy.", 
            "title": "Execution"
        }, 
        {
            "location": "/execution/#pipeline-execution", 
            "text": "At the top level, execution is controlled by standard unix  make .\nThe top-level workflow is as simple as:  Create Scripts/example.json\nmake ipp-start\nadd-sims.sh Scripts/example.json 100 \nmake S=example reduce\nmake S=example graphics  If you go away and forget if the graphics are up to date because\nyou might have added more sims, you can just:  make S=example graphics  and the graphics will be refreshed if there were new simulations added\nsince the last time graphics were made, otherwise, the  make  returns\nimmediately.\nThis is because the graphics target depends on\nthe reduce target, which in turn depends on the  sims/example  directory.\nThis is a powerful feature of  make .  This works automatically when downstream data needs to change in\nresponse to additional upstream data.\nIf the underlying graphics code changes (\"titles in 14 point\") you\nneed to force the graphics refresh by supplying  -B  to  make ,\nwhich forces the rebuild:  make -B S=example graphics", 
            "title": "Pipeline Execution"
        }, 
        {
            "location": "/execution/#tower-of-abstraction", 
            "text": "It's turtles (of varying colors) all the way down.\nMake calls a shell-script driver to do reductions and produce graphics.\nTypically the shell-script will enforce the naming conventions\non inputs and outputs, and then call a matlab or python script to do\nthe actual processing.\nSo, there are three levels of abstraction: the make target,\nthe shell driver, and the 'doing' routine, in matlab or python.  The  Makefile  lists the targets at the top of the file.", 
            "title": "Tower of abstraction"
        }, 
        {
            "location": "/execution/#adding-simulations-to-the-ensemble", 
            "text": "Adding simulations is done outside make with the  add-sims.sh \nshell script driver.\nIts general usage is simply:  add-sims.sh SCRIPT N  where  SCRIPT  is the JSON script, and  N  is the number of sims\nto add to the ensemble tied to  SCRIPT .\nThis pushes down to a call to our main driver script for\nExosims,  Local/ipcluster_ensemble_jpl_driver.py .\nThe main function of this driver is to put results (DRM, SPC) in the proper place,\nand to perform logging.  Two options to add-sims are noteworthy:  -P PAR    =  run without ipython parallel, using PAR independent jobs\n-S SEEDS  =  perform one sim for each integer seed, one per line,\n           in the file SEEDS.  Implies -P.  The  -P  option uses the same underlying run code, but\nuses independent jobs (run in parallel using  xargs )\nrather than ipyparallel.  The  -S SEEDS  option allows multiple ensembles to use the same\nset of seeds, so that yield variability due to parameter changes\nis isolated from that due to the simulated universe.\nOne Exosims simulation is run per seed.", 
            "title": "Adding simulations to the ensemble"
        }, 
        {
            "location": "/execution/#ipython-parallel-support", 
            "text": "We added some iPython-parallel (\"ipp\") targets to the  Makefile , which you\ninvoke (for example) like: make ipp-create .\nThe list of targets is as follows:    ipp-create : create an ipython-parallel profile for this mission (use once\n     per directory only).\n     Copies several files into the ipyparallel directory.\n     To undo, see  ipp-nuke , below.    ipp-start : start the ipython-parallel controller and engines\n     Note: If  EXOSIMS_ENGINE_N  (an integer) is exported from the environment,\n     this many engines will be started up, otherwise, the system-default\n     will be used.  To use this, run, from the shell:  $ EXOSIMS_ENGINE_N=8 make ipp-start    ipp-stop : stop the above.  See also  ipp-kill , below.    ipp-status : report status of the controller and engines\n     Note: This attempts to run trivial jobs on the remote engines, so it\n     will not work if the engines are busy with another job.  See  ipp-ps , below.    ipp-ps : use the unix  ps  command to identify the number of running engines    ipp-kill : sometimes  ipp-stop  does not work and engines or controllers\n     are orphaned.   ipp-kill  identifies these by process id, and kills them.    ipp-nuke : deletes your ipython-parallel profile.  The inverse of  ipp-create .\n     (Note: attempts to  ipp-kill  first, so as to not leave engines running.)    As evidenced by the various status and termination commands, sometimes\nusing ipython parallel in this context can be annoying, because you have\nto remember the state of the worker engines.\nIn particular, the engines will have to be restarted (ipp-stop followed by ipp-start)\nwhen the underlying Exosims code changes, because the engines will have a stale copy.", 
            "title": "iPython parallel support"
        }, 
        {
            "location": "/../src-doc/cool-stuff/", 
            "text": "EXOsandbox.reduce_drms\n\n\n\nreduce_drms.py: reduce a pile of DRMs to various summary CSV files\n\n\nusage:\n  reduce_drms.py [ -O outfile ] [ -j N ] DRM [...]\n\n\nwhere:\n  DRM ... is a list of DRM pickles,\nand:\n  -O outfile gives a template (containing exactly two occurrences of %s) for\n     file outputs.  This is optional, but is best to supply.\n  -j N means to use N parallel workers to process the files.  By default,\n     about 2/3 of the available cores will be used (20 on aftac1, 30 on aftac2).\n     If N = 0 or 1, no parallel workers are used, which is helpful for debugging.\n  -D TYPE gives a (string) TYPE that is inserted into the DEBUG variable in the\n     script, and which can be used to print a selected TYPE of debug output.\n\n\nturmon jan 2018, oct 2018", 
            "title": "Cool Stuff"
        }
    ]
}